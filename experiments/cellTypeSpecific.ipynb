{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d7ff8d",
   "metadata": {},
   "source": [
    "## Experiment 1: cellTypeSpecific\n",
    "\n",
    "This experiment studies different options for the base GRN provided to CellOracle, similar to **baseNetwork**. \n",
    "This is a different specific question and a different setup: within a given source (e.g. ANANSE), does the Ko lab ESC data work best with an ESC-specific network structure? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b10c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME=\"baseNetwork_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5207ee00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import importlib\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import celloracle as co\n",
    "\n",
    "#      visualization settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [6, 4.5]\n",
    "plt.rcParams[\"savefig.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b7ef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n",
      "Loading prebuilt promoter base-GRN. Version: hg19_gimmemotifsv5_fpr2\n"
     ]
    }
   ],
   "source": [
    "# Deal with various file paths specific to this project\n",
    "PROJECT_PATH = '/home/ekernf01/Desktop/jhu/research/projects/perturbation_prediction/cell_type_knowledge_transfer/'\n",
    "os.chdir(PROJECT_PATH + \"benchmarking/\")\n",
    "try:\n",
    "    os.makedirs(\"results/\" + EXPERIMENT_NAME)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "sys.path.append(os.path.expanduser(PROJECT_PATH + 'networks/load_networks'))\n",
    "sys.path.append(os.path.expanduser(PROJECT_PATH + 'perturbations/load_perturbations')) \n",
    "sys.path.append(os.path.expanduser(PROJECT_PATH + 'benchmarking/evaluator')) \n",
    "import evaluator\n",
    "import load_networks\n",
    "import load_perturbations\n",
    "importlib.reload(evaluator) \n",
    "importlib.reload(load_networks) \n",
    "importlib.reload(load_perturbations)\n",
    "os.environ[\"GRN_PATH\"]           = PROJECT_PATH + \"networks/networks\"\n",
    "os.environ[\"PERTURBATION_PATH\"]  = PROJECT_PATH + \"perturbations/perturbations\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b4afab",
   "metadata": {},
   "source": [
    "### Networks setup\n",
    "\n",
    "This experiment aims to test a variety of published sparse regulatory network structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80271883",
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = {\n",
    "    'dense': evaluator.makeRandomNetwork(density = 1),\n",
    "    'ANANSE_all': evaluator.networkEdgesToMatrix(load_networks.load_grn_all_subnetworks(\"ANANSE\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subnetwork in load_networks.list_subnetworks(\"ANANSE\"):\n",
    "    print(\"Loading \" + network)\n",
    "    if not network in networks:\n",
    "        networks[network] = evaluator.networkEdgesToMatrix(load_networks.load_grn_by_subnetwork(\"ANANSE\", network))\n",
    "    gc.collect()\n",
    "    \n",
    "# One more network used in a reprogramming-related project\n",
    "networks[\"mogrify\"] = pd.concat([networks[n] for n in ['MARA_FANTOM4','STRING']])\n",
    "\n",
    "network_sizes = pd.DataFrame({bn:evaluator.countMatrixEdges(networks[bn]) for bn in networks}, index = [\"numEdges\"])\n",
    "network_sizes = network_sizes.T.reset_index().rename({\"index\":\"network\"}, axis = 1)\n",
    "network_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7942cbfa",
   "metadata": {},
   "source": [
    "### Memory consumption\n",
    "\n",
    "This experiment has been a little problematic recently in terms of memory consumed. We can check on that briefly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db0db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({bn:sys.getsizeof(networks[bn])/1e6 for bn in networks}, index = [\"memory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff366043",
   "metadata": {},
   "source": [
    "### Data setup\n",
    "\n",
    "We use the Nakatake et al data. This experiment is on per-cluster versus shared regression models, so we run Leiden clustering at many different resolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f09005",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_lab_esc_data = sc.read_h5ad(os.environ[\"PERTURBATION_PATH\"] + \"/nakatake/\" + \"test.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4163ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_lab_esc_data.obs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowedRegulators = set.intersection(*[set(networks[key].columns) for key in networks])\n",
    "ko_lab_esc_data_train, ko_lab_esc_data_heldout, perturbationsToPredict = \\\n",
    "    evaluator.splitData(ko_lab_esc_data, allowedRegulators, minTestSetSize=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c3c385",
   "metadata": {},
   "source": [
    "### Experimental metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_networks = len(networks.keys())\n",
    "experiments = pd.DataFrame({\"network\":[n for n in networks.keys()], \n",
    "                            \"p\":[1]*n_networks,\n",
    "                            \"threshold_number\":[int(network_sizes['numEdges'].max())]*n_networks,\n",
    "                            \"pruning\":[\"none\"]*n_networks})\n",
    "experiments[\"index\"] = experiments.index\n",
    "experiments.to_csv(\"results/\" + EXPERIMENT_NAME + \"/networkExperiments.csv\")\n",
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f777277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = {\n",
    "    i: evaluator.trainCausalModelAndPredict(expression=ko_lab_esc_data_train,\n",
    "                                  baseNetwork=networks[experiments.loc[i,'network']],\n",
    "                                  memoizationName=\"results/\" + EXPERIMENT_NAME + \"/\" + str(i) + \".celloracle.oracle\", \n",
    "                                  perturbations=perturbationsToPredict,\n",
    "                                  clusterColumnName = ,\n",
    "                                  pruningParameters = {\"p\":experiments.loc[i,'p'], \n",
    "                                                       \"threshold_number\":experiments.loc[i,'threshold_number']}) \n",
    "    for i in experiments.index\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8d5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e34bbb",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We compute the correlation of the predictions with held-out perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c472c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlIndex = ko_lab_esc_data_train.obs[\"perturbation\"]==\"Control\"\n",
    "evaluationResults = {}\n",
    "for i in predictions:\n",
    "    evaluationResults[i] = \\\n",
    "        evaluateCausalModel(ko_lab_esc_data_heldout, \n",
    "                            predictions[i],   \n",
    "                            baseline = ko_lab_esc_data_train[controlIndex,:].X.mean(axis=0),     \n",
    "                            doPlots=False)[0]\n",
    "    evaluationResults[i][\"index\"] = i\n",
    "evaluationResults = pd.concat(evaluationResults)\n",
    "evaluationResults = evaluationResults.merge(experiments, how = \"left\")\n",
    "evaluationResults = pd.DataFrame(evaluationResults.to_dict())\n",
    "evaluationResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66343fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noPredictionMade = evaluationResults.iloc[[x==0 for x in evaluationResults[\"spearman\"]],:]['perturbation']\n",
    "noPredictionMade = set(noPredictionMade)\n",
    "noPredictionMade\n",
    "evaluationResults[\"somePredictionRefused\"] = evaluationResults[\"perturbation\"].isin(noPredictionMade) \n",
    "evaluationResults.to_csv(\"../results/\"+ EXPERIMENT_NAME +\"/networksExperimentEvaluation.csv\")\n",
    "evaluationResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522879c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseNetworkComparisonFigure = sns.FacetGrid(evaluationResults[~evaluationResults['somePredictionRefused']], \n",
    "                                            col = 'pruning',\n",
    "                                            sharey = False, \n",
    "                                            height=5, \n",
    "                                            aspect=1).set(title = \"Performance\")\n",
    "baseNetworkComparisonFigure.map(sns.violinplot, \"spearman\", \"network\", \n",
    "                                palette=[\"r\", \"b\", \"k\", \"y\", \"g\"]\n",
    "                               ).add_legend()\n",
    "baseNetworkComparisonFigure.set(ylabel=\"Spearman correlation\\nminus average over all methods\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ee7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = evaluationResults[~evaluationResults['somePredictionRefused']]\n",
    "summary = summary.groupby([\"pruning\", \"network\"]).mean()[[\"spearman\"]].reset_index([\"pruning\", \"network\"])\n",
    "summary = summary.merge(network_sizes)\n",
    "summary.sort_values(['pruning', 'network'], inplace=True)\n",
    "summary.to_csv(\"../results/\" + EXPERIMENT_NAME + \"/networksExperimentEvaluationSummary.csv\")\n",
    "print(summary)\n",
    "baseNetworkComparisonFigureCompact = sns.scatterplot(data=summary[[p!=\"harsh\" for p in summary[\"pruning\"]]],\n",
    "                x='numEdges',\n",
    "                y='spearman', \n",
    "                hue='network')\n",
    "baseNetworkComparisonFigureCompact.set_xscale(\"log\")\n",
    "baseNetworkComparisonFigureCompact.set(title=\"Density vs performance\")\n",
    "baseNetworkComparisonFigureCompact.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e93a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
